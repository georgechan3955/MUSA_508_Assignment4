---
title: "HW4"
author: "Xiayuanshan Gao, Jiahang Li, Yuhao Chen"
date: "2024-04-17"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    number_sections: yes
    theme: cosmo 
    highlight: tango    
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = FALSE,cache = TRUE)
options(scipen=10000000)
library(RSocrata)
library(tidyverse)
library(kableExtra)
library(caret)
library(knitr) 
library(pscl)
library(plotROC)
library(pROC)
library(lubridate)
library(ggplot2)
library(gridExtra)

palette5 <- c("#eff3ff","#bdd7e7","#6baed6","#3182bd","#08519c")
palette4 <- c("#D2FBD4","#92BCAB","#527D82","#123F5A")
palette2 <- c("#6baed6","#08519c")
```

# Intro



```{r cars}
recidivism <- 
  read.socrata("https://data.ojp.usdoj.gov/Courts/NIJ-s-Recidivism-Challenge-Full-Dataset/ynf5-u8nk")
recidivism <- recidivism %>%
   mutate(recidivism_within_3years_numreic = case_when(
    recidivism_within_3years == "true" ~ 1,
    recidivism_within_3years == "false" ~ 0,
    TRUE ~ NA_integer_  # Handles any unexpected values
  ))


recidivism <- recidivism %>%
  drop_na(gender, race, age_at_release, supervision_level_first, education_level,
                   prison_offense, prison_years, violations, residence_puma,
                   supervision_risk_score_first, percent_days_employed, jobs_per_year,
                   avg_days_per_drugtest, drugtests_thc_positive, drugtests_meth_positive,
                   drugtests_cocaine_positive)

```


# Exploratory Analysis - Recidivism


```{r cache = TRUE, warning = FALSE, message = FALSE}
ggplot(data = recidivism) +
  geom_bar(aes(recidivism_within_3years,fill = recidivism_within_3years),width = 0.4) +
          scale_fill_manual(values = palette2,
                          name = 'Recidivism') +
  labs(x="Recidivism", y="Count", 
           title = "Non-recidivism vs.Recidivism\n",
       caption = 'Figure 2.1') +
      theme(legend.position = "none") 
```

## Categorical Variables

```{r fig.height=12, fig.width=12, message=FALSE, warning=FALSE, cache=TRUE}
cat_var <- recidivism %>%
  select(recidivism_within_3years, gender, race, age_at_release, supervision_level_first, education_level, prison_offense, prison_years, violations,prior_arrest_episodes_felony,prior_arrest_episodes_misd,delinquency_reports,residence_changes,prior_conviction_episodes_6,prior_conviction_episodes_5,prior_conviction_episodes_4,prior_conviction_episodes_3,prior_conviction_episodes_2,prior_conviction_episodes_1,prior_conviction_episodes_7) %>%
  pivot_longer(cols = -recidivism_within_3years, names_to = "Variable", values_to = "value") %>%
  count(Variable, value, recidivism_within_3years) %>%
  ggplot(aes(x = value, y = n, fill = recidivism_within_3years)) + 
    geom_bar(stat = "identity", position = "dodge") +
    facet_wrap(~Variable, scales = "free", ncol = 4,
               labeller = labeller(Variable = c(
                 gender = "Gender",
                 race = "Race",
                 age_at_release = "Age at Release",
                 supervision_level_first = "Supervision Level",
                 education_level = "Education Level",
                 prison_offense = "Prison Offense",
                 prison_years = "Years in Prison",
                 violations = "Violations",
                 prior_arrest_episodes_felony = "Prior Arrest Episodes Felony",
                 prior_arrest_episodes_misd = "Prior Arrest Episodes Misd",
                 delinquency_reports="Delinquency Reports",
                 residence_changes = "Residence Changes",
                 prior_conviction_episodes_7 = "Prior Conviction Episodes:Gun Charges",
                 prior_conviction_episodes_6 = "Prior Conviction Episodes:Domestic Violence Charges",
                 prior_conviction_episodes_5 = "Prior Conviction Episodes:Probation Violation Charges",
                 prior_conviction_episodes_4 = "Prior Conviction Episodes:Drug",
                 prior_conviction_episodes_3 = "Prior Conviction Episodes:Property",
                 prior_conviction_episodes_2 = "Prior Conviction Episodes:Violence",
                 prior_conviction_episodes_1 = "Prior Conviction Episodes:Misdemeanor",
                 employment_exempt = "Employment Exempt"))) +
    scale_fill_manual(values = palette2, name = "Recidivism_within_3years") +
    labs(x = "Category", y = "Count",
         title = "Feature Associations with the Likelihood of Recidivism within 3 Years",
         subtitle = "Categorical Outcomes") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8), # Specify once
          plot.subtitle = element_text(size = 12, face = "italic"),
          plot.title = element_text(size = 18, face = "bold"),
          axis.text.y = element_text(size = 8),
          axis.title = element_text(size = 9),
          panel.background = element_blank(),
          panel.border = element_rect(colour = "grey", fill = NA, linewidth = 0.8))

print(cat_var)
```







## Chi square
```{r cache = TRUE, warning = FALSE, message = FALSE,fig.width=10, fig.height=10}
cat_var <- recidivism %>%
  select(recidivism_within_3years, gender, race, age_at_release, supervision_level_first, education_level, prison_offense, prison_years, violations)

chi_var <- c("gender", "race", "age_at_release", "supervision_level_first", "education_level", "prison_offense", "prison_years", "violations")
label_map <- c(gender = "Gender", race = "Race", age_at_release = "Age at Release",
               supervision_level_first = "Supervision Level First", education_level = "Education Level",
               prison_offense = "Prison Offense", prison_years = "Years in Prison", violations = "Violations")

chi_square_results <- data.frame(
  Variable = character(),
  Df = integer(),
  X_Squared = numeric(),
  P_Value = numeric(),
  stringsAsFactors = FALSE
)


for (var in chi_var) {
  contingency_table <- table(cat_var[[var]], cat_var$recidivism_within_3years)
  chi_square_test <- tryCatch({
    chisq.test(contingency_table)
  }, warning = function(w) {
    message("Warning for ", var, ": ", w$message)
    return(NULL)  # Return NULL if there's a warning
  }, error = function(e) {
    message("Error for ", var, ": ", e$message)
    return(NULL)  # Return NULL if there's an error
  })


  if (!is.null(chi_square_test)) {
    chi_square_results <- rbind(chi_square_results, data.frame(
      Variable = label_map[var],
      Df = chi_square_test$parameter,
      X_Squared = chi_square_test$statistic,
      P_Value = chi_square_test$p.value
    ))
  }
}
chi_square_results <- chi_square_results[, -1]

# Use the label_map you created earlier to set the row names to the descriptive labels
rownames(chi_square_results) <- label_map[chi_var]

# Generate the table without the first column of code variable names
kable(chi_square_results, col.names = c("Degrees of Freedom", "Chi-Squared", "P-Value")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(general_title = "\n", general = "Table 1: Chi-square Test Results for Recidivism Variables")
```

## Numeric Variables
```{r cache = TRUE, warning = FALSE, message = FALSE,fig.width=10, fig.height=10}
numeric_var <- recidivism %>% 
  select(recidivism_within_3years, supervision_risk_score_first, percent_days_employed, jobs_per_year, avg_days_per_drugtest, drugtests_thc_positive, drugtests_meth_positive,drugtests_cocaine_positive)


numeric_var %>%
  gather(Variable, value, -recidivism_within_3years) %>%
    ggplot(aes(recidivism_within_3years, value, fill=recidivism_within_3years)) + 
      geom_bar(position = "dodge", stat = "summary", fun = "mean") + 
      facet_wrap(~Variable, scales = "free", ncol = 4, labeller= labeller(Variable = c(
                     `supervision_risk_score_first` = "Supervision Risk Score",
                     `percent_days_employed` = "Percent Days Employed",
                     `jobs_per_year` = "Jobs Per Year",
                     `avg_days_per_drugtest` = "Avg Days Per Drugtest",
                     `drugtests_thc_positive` = "Drugtests_THC_Positive",
                     `drugtests_meth_positive` = "Drugtests_Meth_Positive",
                     `drugtests_cocaine_positive`= "Drugtests_Cocaine_Positive"))) +
      scale_fill_manual(values = palette2) +
      labs(x="Recidivism_within_3years", y="Value", 
           title = "Feature Associations with the Likelihood of Recidivism",
           subtitle = "Numeric features") +
      theme(legend.position = "none") +
    theme(plot.subtitle = element_text(size = 12,face = "italic"),
        plot.title = element_text(size = 18, face = "bold"), 
        axis.text.x=element_text(size=10),
        axis.text.y=element_text(size=10), 
        axis.title=element_text(size=9), 
        panel.background = element_blank(),
        panel.border = element_rect(colour = "grey", fill=NA, linewidth =0.8))
```





```{r fig.height=10, fig.width=16, message=FALSE, warning=FALSE, cache=TRUE}
numeric_var %>%
    gather(Variable, value, -recidivism_within_3years) %>%
    ggplot() + 
    geom_density(aes(value, color=recidivism_within_3years), fill = "transparent") + 
   facet_wrap(~Variable, scales = "free", ncol = 4, labeller= labeller(Variable = c(
                     `residence_puma` = "Residence PUMA",
                     `supervision_risk_score_first` = "Supervision Risk Score",
                     `percent_days_employed` = "Percent Days Employed",
                     `jobs_per_year` = "Jobs Per Year",
                     `avg_days_per_drugtest` = "Avg Days Per Drugtest",
                     `drugtests_thc_positive` = "Drugtests_THC_Positive",
                     `drugtests_meth_positive` = "Drugtests_Meth_Positive",
                     `drugtests_cocaine_positive`= "Drugtests_Cocaine_Positive"))) +
  scale_color_manual(values = palette2) +
    labs(title = "Feature Distributions Based on Recidivism",
         subtitle = "Continous features") +
  theme(plot.subtitle = element_text(size = 12,face = "italic"),
        plot.title = element_text(size = 18, face = "bold"), 
        axis.text.x=element_text(size=9),
        axis.text.y=element_text(size=9), 
        axis.title=element_text(size=9), 
        panel.background = element_blank(),
        panel.border = element_rect(colour = "grey", fill=NA, linewidth =0.8))
```



## ANOVA TEST

```{r}
numeric_var <- recidivism %>%
  select(recidivism_within_3years, supervision_risk_score_first, percent_days_employed,
         jobs_per_year, avg_days_per_drugtest, drugtests_thc_positive,
         drugtests_meth_positive, drugtests_cocaine_positive) %>%
  na.omit()

# Define ANOVA variables and corresponding new readable names
anova_var <- c("supervision_risk_score_first", "percent_days_employed", "jobs_per_year",
               "avg_days_per_drugtest", "drugtests_thc_positive", "drugtests_meth_positive",
               "drugtests_cocaine_positive")

new_names <- c("Supervision Risk Score", "Percent Days Employed", "Jobs Per Year",
               "Avg Days Per Drugtest", "THC Positive Drugtests", "Meth Positive Drugtests",
               "Cocaine Positive Drugtests")

# Initialize the results data frame
anova_results <- data.frame(
  Variable = new_names,  # use new_names for the variable labels
  Df = integer(length(anova_var)),
  Sum_Sq = numeric(length(anova_var)),
  Mean_Sq = numeric(length(anova_var)),
  F_value = numeric(length(anova_var)),
  P_Value = numeric(length(anova_var)),
  stringsAsFactors = FALSE
)

# Run ANOVA for each variable
for (i in seq_along(anova_var)) {
  var <- anova_var[i]
  
  # Perform ANOVA
  anova_result <- aov(reformulate('recidivism_within_3years', response = var), data = numeric_var)
  
  # Extract the summary
  summary_data <- summary(anova_result)[[1]]
  
  # Fill the results data frame
  anova_results[i, "Df"] <- summary_data["Df"][1]
  anova_results[i, "Sum_Sq"] <- summary_data["Sum Sq"][1]
  anova_results[i, "Mean_Sq"] <- summary_data["Mean Sq"][1]
  anova_results[i, "F_value"] <- summary_data["F value"][1]
  anova_results[i, "P_Value"] <- summary_data["Pr(>F)"][1]
}

# Output the results
anova_results %>%
  kable(col.names = c("Variable", "Degrees of Freedom", "Sum Sq", "Mean Sq", "F value", "P-Value")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(general_title = "\n", general = "Table 2: ANOVA Results for Numeric Variables")
```








# Logistic Regression


We then fit a logistic regression containing the following variables: 

Gender

Race

Age_at_release

Dependents

Supervision_level_first

Education_level

Prison_years

Prison_offense

Violations

Supervision_risk_score_first

Percent_days_employed

Jobs_per_year

Drugtests_thc_positive

Drugtests_cocaine_positive

Drugtests_meth_positive

Gang_affiliated

Prior_arrest_episodes_felony

Prior_arrest_episodes_misd

Prior_arrest_episodes_property

prior_conviction_episodes_6: Prior Conviction Episodes:Domestic Violence Charges

prior_conviction_episodes_5: Prior Conviction Episodes:Probation Violation Charges

prior_conviction_episodes_4: Prior Conviction Episodes:Drug

prior_conviction_episodes_3: Prior Conviction Episodes:Property

prior_conviction_episodes_2: Prior Conviction Episodes:Violence

prior_conviction_episodes_1: Prior Conviction Episodes:Misdemeanor

Prior_revocations_probation

Prior_revocations_parole

Delinquency_reports

Residence_changes

Violations_instruction

We randomly divided our dataset into a training set comprising 65% of the data and a testing set consisting of the remaining 35%. Our analysis revealed that certain variables, including age, specific job categories, contact methods, the month of last contact, outcomes of previous campaigns, the unemployment rate, and consumer price and confidence indices, are significantly correlated with recidivism, each showing a p-value of less than 0.05. Although we experimented with categorizing age and job numbers to generate new variables, this approach reduced the model's accuracy. Consequently, we decided to retain the original variables for our analysis


## Feature Engineering
```{r cache = TRUE, warning = FALSE, message = FALSE}
# age
recidivism <-recidivism %>%
  mutate(age = case_when(
    age_at_release == "18-22"  ~ "Gen Z",
    age_at_release =="38-42" |age_at_release == "43-47" |age_at_release == "48 or older"  ~ "Gen X",
    age_at_release == "23-27" |age_at_release == "28-32" |age_at_release == "33-37" ~ "Millenials"))

recidivism <-recidivism %>%
  mutate(jobnumber = cut(jobs_per_year,
                        breaks = c(-Inf, 1, 5, Inf),  # Define intervals, including all numbers
                        labels = c("0-1", "2-5", "6-8"),  # Labels for each interval
                        include.lowest = TRUE) )

recidivism <-recidivism %>%
  mutate(employmentstates = cut(percent_days_employed,
                        breaks = c(-Inf, 0, 0.99, Inf),  # Define intervals, including all numbers
                        labels = c("Unemployed", "Parttime emplyed", "Employed"),  # Labels for each interval
                        include.lowest = TRUE) )

```



```{r}
set.seed(479)
trainIndex <- createDataPartition(y = paste(recidivism$race) , p = .65,
                                  list = FALSE,
                                  times = 1)
```



Based on the result, we can tell that : 

```{r}
recidivismTrain <- recidivism[ trainIndex,]
recidivismTest  <- recidivism[-trainIndex,]

recidivismModel <- glm(recidivism_within_3years_numreic ~ .,
                  data=recidivismTrain %>% 
                    dplyr::select(recidivism_within_3years_numreic,gender,race,age_at_release,dependents, supervision_level_first,education_level,prison_years,prison_offense,violations,supervision_risk_score_first, percent_days_employed,jobs_per_year,drugtests_thc_positive,drugtests_cocaine_positive, drugtests_meth_positive,gang_affiliated,prior_arrest_episodes_felony,prior_arrest_episodes_misd,prior_arrest_episodes_property,prior_conviction_episodes_6,prior_conviction_episodes_5,prior_conviction_episodes_4,prior_conviction_episodes_3,prior_conviction_episodes_2,prior_conviction_episodes_1,prior_revocations_probation,prior_revocations_parole,delinquency_reports,residence_changes,violations_instruction), family="binomial" (link="logit"))

# Load necessary libraries
library(dplyr)
library(knitr)
library(kableExtra)

# Assuming recidivismModel and previous steps have been correctly run
recidivism_sum <- summary(recidivismModel)
coefficients_table <- as.data.frame(recidivism_sum$coefficients)

# Apply significance stars based on p-values
coefficients_table$significance <- ifelse(coefficients_table$`Pr(>|z|)` < 0.001, '***',
                                         ifelse(coefficients_table$`Pr(>|z|)` < 0.01, '**',
                                                ifelse(coefficients_table$`Pr(>|z|)` < 0.05, '*',
                                                       ifelse(coefficients_table$`Pr(>|z|)` < 0.1, '.', ''))))

# Format p-values with significance
coefficients_table$p_value <- paste0(round(coefficients_table$`Pr(>|z|)`, digits = 3), coefficients_table$significance)

# Rename columns for clarity
names(coefficients_table) <- gsub("prior_conviction_episodes_6true", "Prior_Conviction_Episodes_DomesticViolenceChargestrue", names(coefficients_table))
names(coefficients_table) <- gsub("prior_conviction_episodes_5", "Prior_Conviction_Episodes_PPViolationCharges", names(coefficients_table))
names(coefficients_table) <- gsub("prior_conviction_episodes_4", "Prior_Conviction_Episodes_Drug", names(coefficients_table))
names(coefficients_table) <- gsub("prior_conviction_episodes_3", "Prior_Conviction_Episodes_Property", names(coefficients_table))
names(coefficients_table) <- gsub("prior_conviction_episodes_2", "Prior_Conviction_Episodes_Violence", names(coefficients_table))
names(coefficients_table) <- gsub("prior_conviction_episodes_1", "Prior_Conviction_Episodes_Misd", names(coefficients_table))

# Print the table with formatting
kable(coefficients_table %>% select(-significance, -`Pr(>|z|)`), align = "r") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(general_title = "\n", general = "Table 3")

```

```{r}
OR <- exp(coefficients(recidivismModel)) #odds ratio (exponentiated coefficients)
OR
```

Visually we now can begin comparing the predictions of recidivism. A negative or 0 value means that there is no recidivism, while a positive or 1 value means that there is recidivism. Strong models will have a peak closer to 0 for the negatives (no recidivism), and a peak closer to 1 for the positives (recidivism). In the following graph we can see that our model is better at prediciting the positives rather than the negatives.

```{r}
testProbs <- data.frame(Outcome = as.factor(recidivismTest$recidivism_within_3years_numreic), Probs = predict(recidivismModel, recidivismTest, type= "response"))
head(testProbs)
```




```{r}
ggplot(testProbs, aes(x = Probs, fill = as.factor(Outcome))) + 
  geom_density() +
  facet_grid(Outcome ~ .) +
  scale_fill_manual(values = palette2) + xlim(1, 0) +
  labs(x = "Recidivism", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome") + theme(strip.text.x = element_text(size = 18),
        legend.position = "none")
```


## ROC Curve


We assessed the performance of our enhanced model using the Area Under the Receiver Operating Characteristic Curve (AUC-ROC) metric. The AUC value, which ranges from 0 to 1, gauges the model's discriminatory ability: a score of 0.5 indicates no discrimination (equivalent to random guessing), while a score of 1 signifies perfect discrimination. Generally, an AUC between 0.7 and 0.8 is deemed acceptable, reflecting fair to good model performance. Although there is potential for further refinement, our model's AUC of 0.77 demonstrates its effectiveness in identifying significant patterns in the data and predicting outcomes more accurately than chance.

```{r}
ggplot(testProbs, aes(d = as.numeric(testProbs$Outcome), m = Probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - Recidivism")
```

```{r}
pROC::auc(testProbs$Outcome, testProbs$Probs) # AUC: .73
```

## Confusion Matrix

The Confusion Matrix shows the rate at which we got True Positives (aka Sensitivity), False Positives, True Negatives (aka Specificity) and False Negatives for the 30% threshold.

In this case,
* True Positives: Predicted correctly the individuals who committed recidivism.
* False Positives: We predicted a recidivism but the crime did not recidivate.
* True Negatives: Predicted correctly the individuals who did not commit recidivism.
* False Negatives: We predicted no recidivism but the crime did recidivate.

This analysis prioritizes sensitivity, aiming to predict the likelihood of recidivism accurately. Our model achieves a high sensitivity rate of 0.994 and a lower specificity of 0.31. This outcome is acceptable because, in this context, prioritizing true positive predictions is crucial for minimizing losses and reducing social costs.

```{r}
testProbs <- 
  testProbs %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs$Probs > 0.3 , 1, 0)))

caret::confusionMatrix(testProbs$predOutcome, testProbs$Outcome, 
                       positive = "0")
```


## Cross Validation 

Next, we performed cross validation test for our model. The trainControl parameter is configured to execute 100 k-fold cross-validation runs, producing predicted probabilities (classProbs) for two outcomes: recidivism and non-recidivism. In addition, it generates the Area Under the Curve (AUC), referred to as 'ROC' in the train function, along with confusion matrices for each fold. The cumulative metrics reported in the cvFit output encompass the mean AUC, Sensitivity, and Specificity across all 100 folds. In this instance, our model's ROC is 0.775, Sensitivity is 0.3, and Specificity is 0.94, indicating a balanced performance in both identifying positive cases and correctly ruling out negative ones.



```{r}
customSummary <- function(data, lev = NULL, model = NULL) {
  # Assuming the positive class is labeled as 'True'
  prob <- ifelse(data[, "true"] >= 0.3, lev[2], lev[1])
  
  # Convert probabilities to factors with levels as per the actual outcomes
  prob <- factor(prob, levels = lev)
  
  # Calculate confusion matrix based metrics
  cm <- confusionMatrix(data = prob, reference = data$obs)
  
  # Return a list including metrics like Accuracy, Sensitivity (Recall), and Specificity
  out <- c(cm$overall['Accuracy'], cm$byClass['Sensitivity'], cm$byClass['Specificity'])
  names(out) <- c('Accuracy', 'Sensitivity', 'Specificity')
  out
}

# Set up trainControl with the custom summary function
ctrl <- trainControl(method = "cv", 
                     number = 100, 
                     classProbs = TRUE, 
                     summaryFunction = customSummary)

# Fit the model
cvFit <- train(recidivism_within_3years ~ .,
               data = recidivism %>% 
                 select(recidivism_within_3years, gender, race, age_at_release, dependents, supervision_level_first, education_level, prison_years, prison_offense, violations, supervision_risk_score_first, percent_days_employed, jobs_per_year, drugtests_thc_positive, drugtests_cocaine_positive, drugtests_meth_positive, gang_affiliated, prior_arrest_episodes_felony, prior_arrest_episodes_misd, prior_arrest_episodes_property, prior_conviction_episodes_6, prior_conviction_episodes_5, prior_conviction_episodes_4, prior_conviction_episodes_3, prior_conviction_episodes_2, prior_conviction_episodes_1, prior_revocations_probation, prior_revocations_parole, delinquency_reports, residence_changes, violations_instruction),
               method = "glm", 
               family = "binomial",
               metric = "Accuracy",  # Now using Accuracy or whichever metric you prefer
               trControl = ctrl)

# Print the fit model
print(cvFit)
```


The figure below plots the distribution of AUC, Sensitivity, and Specificity across the 100 folds. The tighter each distribution is to its mean, the more generalizable the model. Based on the result, our model generalizes well to ROC, sensitivity and specificity. To be more specific, our model generalizes well with respect to the rate it correctly predicts No_recidivism and recidivism. Our model is consistent in how it predicts the outcome,recidivism.



```{r}
dplyr::select(cvFit$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#6baed6") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#08519c", linetype = 3, size = 1.5) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
         subtitle = "Across-fold mean reprented as dotted lines")

```

# Generalizability

This section contrasts observed and predicted recidivism rates given the 30% threshold, focusing on the implications for racial and racial-gender fairness.

## Racial Fairness

The following chart illustrates a higher recidivism rate for Black individuals compared to White individuals, there is a higher recidivism rate among black individuals than white individuals.

```{r}
recidivism %>%
    group_by(recidivism_within_3years, race) %>%
    summarize(n = n()) %>%
    mutate(freq = n / sum(n)) %>% filter(recidivism_within_3years == "true") %>%
    ggplot(aes(reorder(race, -freq), freq)) +
    geom_bar(stat = "identity", position = "dodge", fill = palette2) +
    labs(title = "Recidivism rate by race",
         y = "Rate", x = "Race") +
    theme_minimal() + theme(axis.text.x = element_text(angle = 0, hjust = 1))
```



```{r}
reg.noRace <- glm(recidivism_within_3years_numreic ~ ., data = 
                    recidivismTrain %>% dplyr::select(recidivism_within_3years_numreic,gender,age_at_release,dependents, supervision_level_first,education_level,prison_years,prison_offense,violations,supervision_risk_score_first, percent_days_employed,jobs_per_year,drugtests_thc_positive,drugtests_cocaine_positive, drugtests_meth_positive,gang_affiliated,prior_arrest_episodes_felony,prior_arrest_episodes_misd,prior_arrest_episodes_property,prior_conviction_episodes_6,prior_conviction_episodes_5,prior_conviction_episodes_4,prior_conviction_episodes_3,prior_conviction_episodes_2,prior_conviction_episodes_1,prior_revocations_probation,prior_revocations_parole,delinquency_reports,residence_changes,violations_instruction),
                family = "binomial"(link = "logit"))

reg.withRace <- glm(recidivism_within_3years_numreic ~ ., data = 
                      recidivismTrain %>% dplyr::select(recidivism_within_3years_numreic,gender,race,age_at_release,dependents, supervision_level_first,education_level,prison_years,prison_offense,violations,supervision_risk_score_first, percent_days_employed,jobs_per_year,drugtests_thc_positive,drugtests_cocaine_positive, drugtests_meth_positive,gang_affiliated,prior_arrest_episodes_felony,prior_arrest_episodes_misd,prior_arrest_episodes_property,prior_conviction_episodes_6,prior_conviction_episodes_5,prior_conviction_episodes_4,prior_conviction_episodes_3,prior_conviction_episodes_2,prior_conviction_episodes_1,prior_revocations_probation,prior_revocations_parole,delinquency_reports,residence_changes,violations_instruction),
                family = "binomial"(link = "logit"))

```


```{r}
testProbs_race <- 
  data.frame(class = recidivismTest$recidivism_within_3years_numreic,
             probs = predict(reg.noRace, recidivismTest, type = "response"),
             Race = recidivismTest$race)
```

Furthermore, when comparing observed and predicted recidivism rates by race, the model appears to predict higher rates for both Black and White groups, with a slightly larger disparity for Black individuals, which means the recidivism among black individuals are over-predict.

```{r}
mutate(testProbs_race, predClass = ifelse(probs >= .3, 1, 0)) %>%
  group_by(Race) %>%
  summarize(Observed.recidivism = sum(class) / n(),
            Predicted.recidivism = sum(predClass) / n()) %>%
  gather(Variable, Value, -Race) %>%
  ggplot(aes(Race, Value)) +
    geom_bar(aes(fill = Race), position="dodge", stat="identity") +
    scale_fill_manual(values = palette2) +
    facet_wrap(~Variable) +
    labs(title = "Observed and predicted recidivism", x = "Race", y = "Rate") +
    theme_minimal() + theme(axis.text.x = element_text(angle = 0, hjust = 1))
```


```{r}
iterateThresholds <- function(data, observedClass, predictedProbs, group) {
  observedClass <- enquo(observedClass)
  predictedProbs <- enquo(predictedProbs)
  group <- enquo(group)
  x = .01
  all_prediction <- data.frame()
  
  if (missing(group)) {
  
    while (x <= 1) {
    this_prediction <- data.frame()
    
    this_prediction <-
      data %>%
      mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
      count(predclass, !!observedClass) %>%
      summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
                Count_TP = sum(n[predclass==1 & !!observedClass==1]),
                Count_FN = sum(n[predclass==0 & !!observedClass==1]),
                Count_FP = sum(n[predclass==1 & !!observedClass==0]),
                Rate_TP = Count_TP / (Count_TP + Count_FN),
                Rate_FP = Count_FP / (Count_FP + Count_TN),
                Rate_FN = Count_FN / (Count_FN + Count_TP),
                Rate_TN = Count_TN / (Count_TN + Count_FP),
                Accuracy = (Count_TP + Count_TN) / 
                           (Count_TP + Count_TN + Count_FN + Count_FP)) %>%
      mutate(Threshold = round(x,2))
    
    all_prediction <- rbind(all_prediction,this_prediction)
    x <- x + .01
  }
  return(all_prediction)
  }
  else if (!missing(group)) { 
   while (x <= 1) {
    this_prediction <- data.frame()
    
    this_prediction <-
      data %>%
      mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
      group_by(!!group) %>%
      count(predclass, !!observedClass) %>%
      summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
                Count_TP = sum(n[predclass==1 & !!observedClass==1]),
                Count_FN = sum(n[predclass==0 & !!observedClass==1]),
                Count_FP = sum(n[predclass==1 & !!observedClass==0]),
                Rate_TP = Count_TP / (Count_TP + Count_FN),
                Rate_FP = Count_FP / (Count_FP + Count_TN),
                Rate_FN = Count_FN / (Count_FN + Count_TP),
                Rate_TN = Count_TN / (Count_TN + Count_FP),
                Accuracy = (Count_TP + Count_TN) / 
                           (Count_TP + Count_TN + Count_FN + Count_FP)) %>%
      mutate(Threshold = round(x, 2))
    
    all_prediction <- rbind(all_prediction, this_prediction)
    x <- x + .01
  }
  return(all_prediction)
  }
}
```


In the following breakdown plot by confusion matrix, the model exhibits higher predictive accuracy for White individuals and tends to predict recidivism more accurately for this group. 

**False Positive**:For Black individuals, the model has a higher false positive rate, suggesting a tendency to over-predict recidivism. 

**False Negative**: The higher false negative rate for White individuals indicates a tendency to under-predict recidivism. 

In the meantime the model performs better in correctly identifying White individuals who will not recidivate and predicting recidivism for Black individuals. 

**Thus, for black individuals, the model has risk incorrectly predict the non-recidivism while perform better in predicting recidivism; and the situation is reversed for white individuals.**

```{r}
testProbs_race.thresholds <- 
  iterateThresholds(data=testProbs_race, observedClass = class, 
                    predictedProbs = probs, group = Race)

filter(testProbs_race.thresholds, Threshold == .3)  %>%
  dplyr::select(Accuracy, Race, starts_with("Rate")) %>%
  gather(Variable, Value, -Race) %>%
    ggplot(aes(Variable, Value, fill = Race)) +
      geom_bar(aes(fill = Race), position = "dodge", stat = "identity") +
      scale_fill_manual(values = palette2) +
      labs(title="Confusion matrix rates by race",
           subtitle = "50% threshold", x = "Outcome",y = "Rate") +
      theme_minimal() + theme(axis.text.x = element_text(angle = 0, hjust = 1)) 
```

The following ROC curves compare the model's true positive rate and false positive rate across races. Ideally, the curves should be similar, indicating the model performs equally well for each race. Differences in the curves or AUC values could indicate the model is more or less effective for white over black, suggesting a potential racial bias but not significant.

```{r}
# Calculate the ROC curve and AUC for each race
roc_list <- lapply(split(testProbs_race, testProbs_race$Race), function(subdata) {
  roc(response = subdata$class, predictor = subdata$probs)
})

# Create an empty ggplot object with the correct aesthetics
ggroc_combined <- ggplot() + theme_minimal() + 
  labs(title = "ROC Curves by race", x = "False Positive Rate", y = "True Positive Rate") +
  geom_abline(slope=1, intercept=0, linetype="dashed", color = "grey")

# Calculate the position for AUC annotations
max_specificity <- max(sapply(roc_list, function(x) max(1 - x$specificities)))
min_sensitivity <- min(sapply(roc_list, function(x) min(x$sensitivities)))

# Adding ROC curves to the plot with annotations for AUC
for (i in seq_along(roc_list)) {
  roc_data <- roc_list[[i]]
  auc_value <- auc(roc_data)
  ggroc_combined <- ggroc_combined + 
    geom_line(data = data.frame(fp = 1 - roc_data$specificities, tp = roc_data$sensitivities),
              aes(x = fp, y = tp), color = palette2[i], size = 0.5) +
    geom_point(data = data.frame(fp = 1 - roc_data$specificities, tp = roc_data$sensitivities),
               aes(x = fp, y = tp), color = palette2[i], size = 0.3) +
    annotate("text", x = max_specificity - 0.1, y = min_sensitivity + 0.05 * (length(roc_list) - i + 1), 
             label = paste(names(roc_list)[i], "AUC =", round(auc_value, 3)), 
             hjust = 1, color = palette2[i], size = 3.5)
}

print(ggroc_combined)
```


## Racial-Gender Fairness 

The generalizability of the model is further examined by considering not only race but also the intersection of race and gender. The fairness across these intersectional groups is critical, as it may reveal subtle biases not apparent when examining race alone. 

From the following chart we can find that the group of black male has the highest frequency of recidivism, while the lowest recidivism frequency appears to the group of black female.

```{r}

recidivism <- recidivism %>%
  mutate(gender = case_when(
    gender == "F" ~ "Female",
    gender == "M" ~ "Male",
    TRUE ~ as.character(gender)
  ))

recidivism <- recidivism %>%
  mutate(race = case_when(
    race == "BLACK" ~ "Black",
    race == "WHITE" ~ "White",
    TRUE ~ as.character(race)
  ))

recidivism$race_gender <- interaction(recidivism$race, recidivism$gender, sep = "_")

recidivism %>%
    group_by(recidivism_within_3years, race_gender) %>%
    summarize(n = n()) %>%
    mutate(freq = n / sum(n)) %>% filter(recidivism_within_3years == "true") %>%
    ggplot(aes(reorder(race_gender, -freq), freq)) +
    geom_bar(stat = "identity", position = "dodge", fill = palette4) +
    labs(title = "Recidivism rate by race and gender",
         y = "Rate", x = "Race_Gender") +
    theme_minimal() + theme(axis.text.x = element_text(angle = 0, hjust = 1))
```

```{r}
recidivismTrain <- recidivism[ trainIndex,]
recidivismTest  <- recidivism[-trainIndex,]
```



```{r}
reg.norace_gender <- glm(recidivism_within_3years_numreic ~ ., data = 
                    recidivismTrain %>% dplyr::select(recidivism_within_3years_numreic,gender,race,age_at_release,dependents, supervision_level_first,education_level,prison_years,prison_offense,violations,supervision_risk_score_first, percent_days_employed,jobs_per_year,drugtests_thc_positive,drugtests_cocaine_positive, drugtests_meth_positive,gang_affiliated,prior_arrest_episodes_felony,prior_arrest_episodes_misd,prior_arrest_episodes_property,prior_conviction_episodes_6,prior_conviction_episodes_5,prior_conviction_episodes_4,prior_conviction_episodes_3,prior_conviction_episodes_2,prior_conviction_episodes_1,prior_revocations_probation,prior_revocations_parole,delinquency_reports,residence_changes,violations_instruction),
                family = "binomial"(link = "logit"))

reg.withrace_gender <- glm(recidivism_within_3years_numreic ~ ., data = 
                      recidivismTrain %>% dplyr::select(recidivism_within_3years_numreic,gender,race,age_at_release,dependents, supervision_level_first,education_level,prison_years,prison_offense,violations,supervision_risk_score_first, percent_days_employed,jobs_per_year,drugtests_thc_positive,drugtests_cocaine_positive, drugtests_meth_positive,gang_affiliated,prior_arrest_episodes_felony,prior_arrest_episodes_misd,prior_arrest_episodes_property,prior_conviction_episodes_6,prior_conviction_episodes_5,prior_conviction_episodes_4,prior_conviction_episodes_3,prior_conviction_episodes_2,prior_conviction_episodes_1,prior_revocations_probation,prior_revocations_parole,delinquency_reports,residence_changes,violations_instruction),
                family = "binomial"(link = "logit"))

```

```{r}
testProbs_race_gender <- 
  data.frame(class = recidivismTest$recidivism_within_3years_numreic,
             probs = predict(reg.norace_gender, recidivismTest, type = "response"),
             Race_Gender = recidivismTest$race_gender)
```

And then comparing the observation and the predicted result from our model with the breakdown of race-gender groups, the plot below uncovers that all groups are overly predicted, and it is hard to observe a siginicant bias on one group.

```{r fig.width=12}
mutate(testProbs_race_gender, predClass = ifelse(probs >= .3, 1, 0)) %>%
  group_by(Race_Gender) %>%
  summarize(Observed.recidivism = sum(class) / n(),
            Predicted.recidivism = sum(predClass) / n()) %>%
  gather(Variable, Value, -Race_Gender) %>%
  ggplot(aes(Race_Gender, Value)) +
    geom_bar(aes(fill = Race_Gender), position="dodge", stat="identity") +
    scale_fill_manual(values = palette4) +
    facet_wrap(~Variable) +
    labs(title = "Observed and predicted recidivism", x = "Race_Gender", y = "Rate") +
    theme_minimal() + theme(axis.text.x = element_text(angle = 0, hjust = 1))
```

```{r}
iterateThresholds <- function(data, observedClass, predictedProbs, group) {
  observedClass <- enquo(observedClass)
  predictedProbs <- enquo(predictedProbs)
  group <- enquo(group)
  x = .01
  all_prediction <- data.frame()
  
  if (missing(group)) {
  
    while (x <= 1) {
    this_prediction <- data.frame()
    
    this_prediction <-
      data %>%
      mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
      count(predclass, !!observedClass) %>%
      summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
                Count_TP = sum(n[predclass==1 & !!observedClass==1]),
                Count_FN = sum(n[predclass==0 & !!observedClass==1]),
                Count_FP = sum(n[predclass==1 & !!observedClass==0]),
                Rate_TP = Count_TP / (Count_TP + Count_FN),
                Rate_FP = Count_FP / (Count_FP + Count_TN),
                Rate_FN = Count_FN / (Count_FN + Count_TP),
                Rate_TN = Count_TN / (Count_TN + Count_FP),
                Accuracy = (Count_TP + Count_TN) / 
                           (Count_TP + Count_TN + Count_FN + Count_FP)) %>%
      mutate(Threshold = round(x,2))
    
    all_prediction <- rbind(all_prediction,this_prediction)
    x <- x + .01
  }
  return(all_prediction)
  }
  else if (!missing(group)) { 
   while (x <= 1) {
    this_prediction <- data.frame()
    
    this_prediction <-
      data %>%
      mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
      group_by(!!group) %>%
      count(predclass, !!observedClass) %>%
      summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
                Count_TP = sum(n[predclass==1 & !!observedClass==1]),
                Count_FN = sum(n[predclass==0 & !!observedClass==1]),
                Count_FP = sum(n[predclass==1 & !!observedClass==0]),
                Rate_TP = Count_TP / (Count_TP + Count_FN),
                Rate_FP = Count_FP / (Count_FP + Count_TN),
                Rate_FN = Count_FN / (Count_FN + Count_TP),
                Rate_TN = Count_TN / (Count_TN + Count_FP),
                Accuracy = (Count_TP + Count_TN) / 
                           (Count_TP + Count_TN + Count_FN + Count_FP)) %>%
      mutate(Threshold = round(x, 2))
    
    all_prediction <- rbind(all_prediction, this_prediction)
    x <- x + .01
  }
  return(all_prediction)
  }
}
```

In the following breakdown plot by confusion matrix, the model exhibits a similar accuracy for the 4 groups with a relatively lower accuracy rate for while female, which means the model would preform worse in predicting white female's recidivism.

**False Positive**:For male, especially black male, the model has a higher false positive rate, suggesting a tendency to over-predict recidivism. 

**False Negative**: The higher false negative rate for black and white female, especially black female indicates a tendency to under-predict recidivism. 

In the meantime the model performs better in correctly identifying females especially black females who will not recidivate and predicting recidivism for males. 

```{r}
testProbs_Race_Gender.thresholds <- 
  iterateThresholds(data=testProbs_race_gender, observedClass = class, 
                    predictedProbs = probs, group = Race_Gender)

filter(testProbs_Race_Gender.thresholds, Threshold == .3)  %>%
  dplyr::select(Accuracy, Race_Gender, starts_with("Rate")) %>%
  gather(Variable, Value, -Race_Gender) %>%
    ggplot(aes(Variable, Value, fill = Race_Gender)) +
      geom_bar(aes(fill = Race_Gender), position = "dodge", stat = "identity") +
      scale_fill_manual(values = palette4) +
      labs(title="Confusion matrix rates by race and gender",
           subtitle = "50% threshold", x = "Outcome",y = "Rate") +
      theme_minimal() + theme(axis.text.x = element_text(angle = 0, hjust = 1)) 
```


The ROC curves demonstrate the model's performance in distinguishing between recidivism outcomes for different race-gender groups. The AUC values are all relatively similar, with Black Females having a marginally higher AUC, indicating the model's slightly better performance for this group. Overall, the model shows consistent discriminative ability across these categories.

```{r}
# Calculate the ROC curve and AUC for each race
roc_list <- lapply(split(testProbs_race_gender, testProbs_race_gender$Race_Gender), function(subdata) {
  roc(response = subdata$class, predictor = subdata$probs)
})

# Create an empty ggplot object with the correct aesthetics
ggroc_combined <- ggplot() + theme_minimal() + 
  labs(title = "ROC Curves by race", x = "False Positive Rate", y = "True Positive Rate") +
  geom_abline(slope=1, intercept=0, linetype="dashed", color = "grey")

# Calculate the position for AUC annotations
max_specificity <- max(sapply(roc_list, function(x) max(1 - x$specificities)))
min_sensitivity <- min(sapply(roc_list, function(x) min(x$sensitivities)))

# Adding ROC curves to the plot with annotations for AUC
for (i in seq_along(roc_list)) {
  roc_data <- roc_list[[i]]
  auc_value <- auc(roc_data)
  ggroc_combined <- ggroc_combined + 
    geom_line(data = data.frame(fp = 1 - roc_data$specificities, tp = roc_data$sensitivities),
              aes(x = fp, y = tp), color = palette4[i], size = 0.5) +
    geom_point(data = data.frame(fp = 1 - roc_data$specificities, tp = roc_data$sensitivities),
               aes(x = fp, y = tp), color = palette4[i], size = 0.3) +
    annotate("text", x = max_specificity - 0.1, y = min_sensitivity + 0.05 * (length(roc_list) - i + 1), 
             label = paste(names(roc_list)[i], "AUC =", round(auc_value, 3)), 
             hjust = 1, color = palette4[i], size = 3.5)
}

print(ggroc_combined)
```

In summary, while the model demonstrates a reasonable level of overall discriminative ability as reflected by the ROC curves, Black Males are subject to the model's over-prediction bias. Conversely, the model shows a better predictive accuracy for Black Females, suggesting they are the group for whom the model performs best. This nuanced performance warrants a careful review of the model to ensure equitable outcomes across race and gender intersections.

#  Cost-Benefit Analysis 

As the final step, we conduct a cost-benefit analysis to evaluate
We cite some hypothetical numbers for the cost associated with keeping someone in prison versus the costs associated with recidivism (arrest, trial, etc.). Here are some assumptions we chose:

**Costs of Incarceration:**

Cost of keeping someone in prison per year: $50,000.

*This cost includes expenses for security, food, health care, and administration.*

**Costs of Recidivism:**

Arrest costs: $2,000 per arrest.

Trial and court costs: $15,000 per case.

Probation or parole supervision costs: $4,000 per year.

Average number of arrests for recidivists: 2.

Probability of going to trial if arrested: 0.5.

**Economic Benefits of Avoiding Incarceration:**

Estimated value of productive work if not incarcerated: $30,000 per year.

Cost savings from reduced prison population: $10,000 per year *(due to economies of scale, reduced need for facilities, etc.)*.

With these assumptions, we frame the cost-benefit calculations for each possible outcome of the prediction model:

**True Negative (TN): Individuals correctly predicted not to recidivate and thus not incarcerated.**

Benefit: $50,000 *(cost of incarceration avoided)* + $30,000 *(value of productive work)* + $10,000 *(cost savings)* = $90,000.

**True Positive (TP): Individuals correctly predicted to recidivate and thus incarcerated.**

Cost: $50,000 *(cost of keeping someone in prison)* - $30,000 *(value of productive work not realized)* = $20,000 net cost.

**False Negative (FN): Individuals incorrectly predicted not to recidivate but they do.**

Cost: $2,000 *(arrest costs)* + 0.5 * $15,000 *(trial costs on average)* + 2 * $4,000 *(probation costs for two years)* = $28,000.

**False Positive (FP): Individuals incorrectly predicted to recidivate and thus incarcerated.**

Cost: $50,000 *(unnecessary cost of incarceration)* + $30,000 *(loss of productive work)* + $10,000 *(cost savings not realized)* = $90,000.

```{r}
cost_benefit_table <- testProbs %>%
  count(predOutcome, Outcome) %>%
  summarize(
    True_Negative = sum(n[predOutcome == 0 & Outcome == 0]),
    True_Positive = sum(n[predOutcome == 1 & Outcome == 1]),
    False_Negative = sum(n[predOutcome == 0 & Outcome == 1]),
    False_Positive = sum(n[predOutcome == 1 & Outcome == 0])
  ) %>%
  gather(Variable, Count) %>%
  mutate(
    Revenue = case_when(
      Variable == "True_Negative" ~ Count * 90, # $90,000 net benefit for TN
      Variable == "True_Positive" ~ -Count * 20, # $20,000 net cost for TP
      Variable == "False_Negative" ~ -Count * 28, # $28,000 net cost for FN
      Variable == "False_Positive" ~ -Count * 90 # $90,000 net cost for FP
    )
  ) %>%
  bind_cols(data.frame(Description = c(
    "We correctly predicted no recidivism",
    "We correctly predicted a recidivism",
    "We predicted no recidivism but the crime did recidivate",
    "We predicted a recidivism but the crime did not recidivate"
  )))

kable(cost_benefit_table, caption = "Cost/Benefit Analysis") %>%
  kable_styling()
```

The cost-benefit analysis table and corresponding graphs provide a stark visualization of the economic impact of recidivism predictions at varying thresholds. In the analysis, the number of true negatives and true positives dominates the count of outcomes, indicating a predictive model reasonably attuned to actual outcomes.

With true negatives, we witness a substantial benefit, as these cases represent individuals correctly predicted not to recidivate, saving the system the cost of incarceration and the associated lost productivity. Conversely, the costliest scenario emerges from false positives. 

```{r}
iterateThresholds <- function(data) {
  x <- 0.01
  all_prediction <- data.frame()
  while (x <= 1) {
    this_prediction <- data %>%
      mutate(predOutcome = ifelse(Probs > x, 1, 0)) %>%
      count(predOutcome, Outcome) %>%
      summarize(
        True_Negative = sum(n[predOutcome == 0 & Outcome == 0]),
        True_Positive = sum(n[predOutcome == 1 & Outcome == 1]),
        False_Negative = sum(n[predOutcome == 0 & Outcome == 1]),
        False_Positive = sum(n[predOutcome == 1 & Outcome == 0])
      ) %>%
      gather(Variable, Count) %>%
      mutate(
        Revenue = case_when(
          Variable == "True_Negative" ~ Count * 90,  # $90,000 net benefit for TN
          Variable == "True_Positive" ~ -Count * 20, # $20,000 net cost for TP
          Variable == "False_Negative" ~ -Count * 28, # $28,000 net cost for FN
          Variable == "False_Positive" ~ -Count * 90  # $90,000 net cost for FP
        ),
        Threshold = x
      )
    all_prediction <- rbind(all_prediction, this_prediction)
    x <- x + .01
  }
  return(all_prediction)
}

```

```{r}
whichThreshold <- iterateThresholds(testProbs)

whichThreshold_revenue <- 
whichThreshold %>% 
    group_by(Threshold) %>% 
    summarize(Revenue = sum(Revenue))

whichThreshold %>%
  ggplot(.,aes(Threshold, Revenue, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = palette5[c(5, 1:3)]) +    
  labs(title = "Revenue by confusion matrix type and threshold",
       y = "Revenue") +
  theme_minimal() +
  guides(colour=guide_legend(title = "Confusion Matrix")) 
```

As seen in the above and below fugures, revenue begins to normalize or flatten out at 0.75 This means that if as a department we want to maximize our budget, we should only allocate to those in the thresholds between .75 to 1.

```{r}
whichThreshold_revenue <-
  whichThreshold %>%
  mutate(Count_Costs = case_when(
    Variable == "True_Positive" ~ -Count * 20,  # $20,000 net cost for TP
    Variable == "False_Negative" ~ -Count * 28, # $28,000 net cost for FN
    Variable == "False_Positive" ~ -Count * 90, # $90,000 net cost for FP
    Variable == "True_Negative" ~ Count * 90,   # $90,000 net benefit for TN
    TRUE ~ 0  # In case there are other categories, we assume no cost/benefit
  )) %>%
  group_by(Threshold) %>%
  summarize(
    Total_Revenue = sum(Count_Costs)
  )

  ggplot(whichThreshold_revenue)+
  geom_line(aes(x = Threshold, y = Total_Revenue))+
  geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -Total_Revenue)[1,1]))+
    labs(title = "Model Revenues By Threshold For Test Sample",
         subtitle = "Vertical Line Denotes Optimal Threshold")

```
```


# Conclusion


In conclusion, the analysis shows a model that is adept at identifying individuals who are likely to recidivate, specifically benefiting community safety and economic planning. It effectively captures the true positive ratesthose who are likely to benefit from interventionsunderscoring its utility from a social stability perspective.

However, the model struggles with false positives, which could lead to unnecessary social and economic burdens, especially among certain demographic groups. The disproportionate impact on Black Males, in particular, highlights an area for immediate review and adjustment.

For a more balanced approach that maximizes the models strengths and minimizes its weaknesses, it is essential to consider:

1. Reevaluating the model parameters and integrating a broader range of data points, such as spatial characteristics, to refine its predictive accuracy.

2. Implementing strategies to mitigate the potential economic impacts of the model's current limitations, such as targeted outreach and support for those wrongly identified as high risk for recidivism.

3. Ensuring constant monitoring and adjustment of the model to adapt to dynamic social factors and economic conditions, thus ensuring its continued relevance and fairness.

Such steps will ensure that the model does not just serve as a predictive tool but also as a catalyst for constructive interventions, aligning with the overarching goals of community development and economic sustainability.






